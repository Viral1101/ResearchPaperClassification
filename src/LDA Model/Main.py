import nltk
import gensim
import PreProcessing
import Model

if __name__ == '__main__':
    filenames = ['example.pdf']

    preprocessed_files = list()
    for file in filenames:
        preprocessed_files.append(PreProcessing.preprocess(file))

    # Find ngrams of sizes 3-10
    ngram_list = list()
    for i in range(3, 11):
        ngrams = nltk.ngrams(preprocessed_files[0], i)
        for ngram in ngrams:
            ngram_list.append(ngram)

    # Extract the top n-grams based on their count
    ngram_count = 100
    ngram_dict = dict()
    for ngram in ngram_list:
        if ngram not in ngram_dict.keys():
            ngram_dict[ngram] = 1
        else:
            ngram_dict[ngram] += 1

    top_ngram_list = list()
    for i in range(0, ngram_count):
        max_count = 0
        max_trigram = 0
        for trigram in ngram_dict.keys():
            if ngram_dict[trigram] > max_count:
                max_count = ngram_dict[trigram]
                max_trigram = trigram
                ngram_dict[trigram] = 0
        top_ngram_list.append(max_trigram)

    print('\n', top_ngram_list, '\n')

    dictionary = gensim.corpora.Dictionary(preprocessed_files)
    bow_corpus = [dictionary.doc2bow(file) for file in preprocessed_files]

    topic_amount = 3
    topic_list = list()

    lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=topic_amount, id2word=dictionary, passes=100, workers=2)

    # Print Topics generated by LDA
    for i in range(0, topic_amount):
        word_list = list()
        print('Topic: ', i)
        words = lda_model.show_topic(i, 10)
        for word in words:
            word_list.append(word[0])
        topic_list.append(word_list)
        print(word_list)

    # Create word2vec model from PDFs
    word2vec_model = gensim.models.Word2Vec(preprocessed_files, size=256, window=5, min_count=1, workers=4)

    # Encode n-grams using word2vec model
    top_ngrams_encoded = list()
    for ngram in top_ngram_list:
        top_ngrams_encoded.append(PreProcessing.encode_ngram(word2vec_model, ngram))

    # Encode Topics using word2vec model
    topic_list_encoded = list()
    for i in range(0, topic_amount):
        word_list = list()
        words = lda_model.show_topic(i, 10)
        for word in words:
            word_list.append(word[0])
        topic_list_encoded.append(PreProcessing.encode_ngram(word2vec_model, word_list))

    x = list()
    for i in range(0,len(top_ngrams_encoded)):
        row = list()
        row.append(top_ngrams_encoded[i])
        for topic in topic_list_encoded:
            row.extend(topic)
        x.append(row)

    print(len(x))
    print(len(x[99]))

    model_filename = 'model.h5'
    sequential_model = Model.get_model(model_filename)
